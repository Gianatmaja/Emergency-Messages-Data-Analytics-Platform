{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will cover the feature extraction and model training for classifying the disaster messages' categories. We will be using the cleaned dataset, which was previously processed in 2 separate notebooks, namely 'Data Augmentation.ipynb' and 'Data Cleaning.ipynb'. \n",
    "\n",
    "At the end of this notebook, we will save the prediction pipeline so that it can be loaded and used directly in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting-up the Environment\n",
    "\n",
    "Required libraries are first imported, and then the datasets are read into the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/gianatmaja/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn import multioutput\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, fbeta_score, make_scorer\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "Train = pd.read_csv('Cleaned/Train.csv', index_col = [0])\n",
    "Test = pd.read_csv('Cleaned/Test.csv', index_col = [0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at the Data\n",
    "\n",
    "We will print out a section of the data, and look at the columns present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>ID</th>\n",
       "      <th>date</th>\n",
       "      <th>labeled</th>\n",
       "      <th>message</th>\n",
       "      <th>original</th>\n",
       "      <th>language</th>\n",
       "      <th>related</th>\n",
       "      <th>request</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>...</th>\n",
       "      <th>aid_centers</th>\n",
       "      <th>other_infrastructure</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>With the cooperation of First Hawaiian Bank, t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>PEWODEN FIFTH SECTION OF THE DEPARTEMEN OF L'A...</td>\n",
       "      <td>Pewoden 5em Seksyon Depatman Atibonit ap fe no...</td>\n",
       "      <td>ht</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>Today on a call with Dr. Chan, Director Genera...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>YANGON, Jul 08, 2008 (Xinhua via COMTEX News N...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>Throughout the year there were growing signs o...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  ID        date  labeled  \\\n",
       "0      0   1  2010-01-01        0   \n",
       "1      1   2  2010-01-01        1   \n",
       "2      2   3  2010-01-01        1   \n",
       "3      3   4  2010-01-01        0   \n",
       "4      4   5  2010-01-01        1   \n",
       "\n",
       "                                             message  \\\n",
       "0  With the cooperation of First Hawaiian Bank, t...   \n",
       "1  PEWODEN FIFTH SECTION OF THE DEPARTEMEN OF L'A...   \n",
       "2  Today on a call with Dr. Chan, Director Genera...   \n",
       "3  YANGON, Jul 08, 2008 (Xinhua via COMTEX News N...   \n",
       "4  Throughout the year there were growing signs o...   \n",
       "\n",
       "                                            original language  related  \\\n",
       "0                                                NaN       en        1   \n",
       "1  Pewoden 5em Seksyon Depatman Atibonit ap fe no...       ht        1   \n",
       "2                                                NaN       en        1   \n",
       "3                                                NaN       en        1   \n",
       "4                                                NaN       en        1   \n",
       "\n",
       "   request  aid_related  ...  aid_centers  other_infrastructure  \\\n",
       "0        0            1  ...            0                     0   \n",
       "1        0            0  ...            0                     0   \n",
       "2        0            1  ...            0                     0   \n",
       "3        0            1  ...            1                     1   \n",
       "4        0            1  ...            0                     0   \n",
       "\n",
       "   weather_related  floods  storm  fire  earthquake  cold  other_weather  \\\n",
       "0                1       0      1     0           0     0              1   \n",
       "1                1       0      0     0           1     0              0   \n",
       "2                0       0      0     0           0     0              0   \n",
       "3                1       1      1     0           0     0              0   \n",
       "4                0       0      0     0           0     0              0   \n",
       "\n",
       "   direct_report  \n",
       "0              0  \n",
       "1              1  \n",
       "2              0  \n",
       "3              0  \n",
       "4              0  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Helper Functions\n",
    "\n",
    "Here, we will define some helper functions required for training purposes. First, we will define a function which will give us the average of the precision, recall, and the F1-Score for each of target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function that measures mean of f1, precision, recall for classes within a multi-class prediction problem\n",
    "def f1_pre_acc_evaluation(y_true, y_pred): \n",
    "    \n",
    "    report = pd.DataFrame()\n",
    "    \n",
    "    for col in y_true.columns:\n",
    "        # Dictionary from classification report\n",
    "        class_dict = classification_report(output_dict = True, y_true = y_true.loc[:,col], y_pred = y_pred.loc[:,col])\n",
    "    \n",
    "        # Converting to dataframe\n",
    "        eval_df = pd.DataFrame(pd.DataFrame.from_dict(class_dict))\n",
    "        \n",
    "        # Calculate mean\n",
    "        av_eval_df = pd.DataFrame(eval_df.transpose().mean())\n",
    "        \n",
    "        # Transpose to rows\n",
    "        av_eval_df = av_eval_df.transpose()\n",
    "    \n",
    "        # Record result\n",
    "        report = report.append(av_eval_df, ignore_index = True)    \n",
    "    \n",
    "    report.index = y_true.columns\n",
    "    \n",
    "    return report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we will also define below, a function that will help us in preprocessing our text data, by performing text normalization, tokenization, stop words removal, as well as stemming and lemmatization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    \n",
    "    # Normalize text\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text.lower())\n",
    "    \n",
    "    # Get stopwords\n",
    "    stop_words = stopwords.words(\"english\")\n",
    "    \n",
    "    #tokenize\n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "    #stemming\n",
    "    stemmed = [PorterStemmer().stem(w) for w in words]\n",
    "    \n",
    "    #lemmatizing\n",
    "    words_lemmed = [WordNetLemmatizer().lemmatize(w) for w in stemmed if w not in stop_words]\n",
    "   \n",
    "    return words_lemmed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the Dataset\n",
    "\n",
    "Below, we will prepare our dataset for training by splitting it into X_train, X_test, y_train, and y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and testing set\n",
    "X_train = Train['message']\n",
    "y_train = Train.iloc[:,7:]\n",
    "\n",
    "X_test = Test['message']\n",
    "y_test = Test.iloc[:,7:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Pipeline\n",
    "\n",
    "Below, we will build the prediction pipeline. First, we will be using count vectorizer and tf-idf transformer to extract features from our text dataset. Then, we will be training a multi-output random forest classifier on those features. We will fit the pipeline on our training dataset, and see how it performs when we use it to predict on our testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building pipeline\n",
    "pipeline = Pipeline([\n",
    "        ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', multioutput.MultiOutputClassifier(RandomForestClassifier()))\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect',\n",
       "                 CountVectorizer(tokenizer=<function tokenize at 0x7fb004706680>)),\n",
       "                ('tfidf', TfidfTransformer()),\n",
       "                ('clf',\n",
       "                 MultiOutputClassifier(estimator=RandomForestClassifier()))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit pipeline into training set\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will predict on the test dataset below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict test set\n",
    "y_pred = pipeline.predict(X_test)\n",
    "y_pred = pd.DataFrame(y_pred, columns = y_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Evaluate results\n",
    "report = f1_pre_acc_evaluation(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe the precision, recall and F1-Score below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>related</th>\n",
       "      <td>0.786179</td>\n",
       "      <td>0.774017</td>\n",
       "      <td>0.779427</td>\n",
       "      <td>1572.172366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>request</th>\n",
       "      <td>0.899284</td>\n",
       "      <td>0.795555</td>\n",
       "      <td>0.822057</td>\n",
       "      <td>1572.178321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aid_related</th>\n",
       "      <td>0.810601</td>\n",
       "      <td>0.803270</td>\n",
       "      <td>0.805015</td>\n",
       "      <td>1572.161832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medical_help</th>\n",
       "      <td>0.839252</td>\n",
       "      <td>0.700710</td>\n",
       "      <td>0.708548</td>\n",
       "      <td>1572.184122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medical_products</th>\n",
       "      <td>0.943159</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.722181</td>\n",
       "      <td>1572.192443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>search_and_rescue</th>\n",
       "      <td>0.918008</td>\n",
       "      <td>0.729401</td>\n",
       "      <td>0.752104</td>\n",
       "      <td>1572.198092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>security</th>\n",
       "      <td>0.795347</td>\n",
       "      <td>0.717327</td>\n",
       "      <td>0.729566</td>\n",
       "      <td>1572.198779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>military</th>\n",
       "      <td>0.666111</td>\n",
       "      <td>0.684342</td>\n",
       "      <td>0.675055</td>\n",
       "      <td>1572.192290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>water</th>\n",
       "      <td>0.950010</td>\n",
       "      <td>0.790167</td>\n",
       "      <td>0.829515</td>\n",
       "      <td>1572.190229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>food</th>\n",
       "      <td>0.943393</td>\n",
       "      <td>0.852828</td>\n",
       "      <td>0.884631</td>\n",
       "      <td>1572.188855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shelter</th>\n",
       "      <td>0.936517</td>\n",
       "      <td>0.795249</td>\n",
       "      <td>0.832450</td>\n",
       "      <td>1572.188779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clothing</th>\n",
       "      <td>0.937315</td>\n",
       "      <td>0.768161</td>\n",
       "      <td>0.805572</td>\n",
       "      <td>1572.197710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>money</th>\n",
       "      <td>0.880387</td>\n",
       "      <td>0.698196</td>\n",
       "      <td>0.699992</td>\n",
       "      <td>1572.194809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missing_people</th>\n",
       "      <td>0.995998</td>\n",
       "      <td>0.716460</td>\n",
       "      <td>0.731639</td>\n",
       "      <td>1572.198855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>refugees</th>\n",
       "      <td>0.981949</td>\n",
       "      <td>0.713943</td>\n",
       "      <td>0.728493</td>\n",
       "      <td>1572.194809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>death</th>\n",
       "      <td>0.938924</td>\n",
       "      <td>0.724247</td>\n",
       "      <td>0.745303</td>\n",
       "      <td>1572.191679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_aid</th>\n",
       "      <td>0.805608</td>\n",
       "      <td>0.678115</td>\n",
       "      <td>0.669676</td>\n",
       "      <td>1572.183359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>infrastructure_related</th>\n",
       "      <td>0.672962</td>\n",
       "      <td>0.687668</td>\n",
       "      <td>0.680204</td>\n",
       "      <td>1572.193893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transport</th>\n",
       "      <td>0.889635</td>\n",
       "      <td>0.694369</td>\n",
       "      <td>0.695305</td>\n",
       "      <td>1572.190382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buildings</th>\n",
       "      <td>0.874548</td>\n",
       "      <td>0.727207</td>\n",
       "      <td>0.747909</td>\n",
       "      <td>1572.191908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>electricity</th>\n",
       "      <td>0.989093</td>\n",
       "      <td>0.700883</td>\n",
       "      <td>0.703847</td>\n",
       "      <td>1572.196870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tools</th>\n",
       "      <td>0.698626</td>\n",
       "      <td>0.699389</td>\n",
       "      <td>0.699008</td>\n",
       "      <td>1572.199695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hospitals</th>\n",
       "      <td>0.693826</td>\n",
       "      <td>0.697252</td>\n",
       "      <td>0.695533</td>\n",
       "      <td>1572.198626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shops</th>\n",
       "      <td>0.697520</td>\n",
       "      <td>0.698664</td>\n",
       "      <td>0.698091</td>\n",
       "      <td>1572.199389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aid_centers</th>\n",
       "      <td>0.694854</td>\n",
       "      <td>0.697710</td>\n",
       "      <td>0.696278</td>\n",
       "      <td>1572.198855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_infrastructure</th>\n",
       "      <td>0.685624</td>\n",
       "      <td>0.693588</td>\n",
       "      <td>0.689574</td>\n",
       "      <td>1572.196794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weather_related</th>\n",
       "      <td>0.910328</td>\n",
       "      <td>0.879635</td>\n",
       "      <td>0.891541</td>\n",
       "      <td>1572.181908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>floods</th>\n",
       "      <td>0.962282</td>\n",
       "      <td>0.821337</td>\n",
       "      <td>0.862033</td>\n",
       "      <td>1572.190000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>storm</th>\n",
       "      <td>0.913067</td>\n",
       "      <td>0.822865</td>\n",
       "      <td>0.853762</td>\n",
       "      <td>1572.189160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fire</th>\n",
       "      <td>0.696225</td>\n",
       "      <td>0.698321</td>\n",
       "      <td>0.697271</td>\n",
       "      <td>1572.199160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>earthquake</th>\n",
       "      <td>0.972911</td>\n",
       "      <td>0.965148</td>\n",
       "      <td>0.968957</td>\n",
       "      <td>1572.197328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cold</th>\n",
       "      <td>0.951869</td>\n",
       "      <td>0.740596</td>\n",
       "      <td>0.770007</td>\n",
       "      <td>1572.197023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_weather</th>\n",
       "      <td>0.895670</td>\n",
       "      <td>0.692493</td>\n",
       "      <td>0.690802</td>\n",
       "      <td>1572.192061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>direct_report</th>\n",
       "      <td>0.847525</td>\n",
       "      <td>0.719564</td>\n",
       "      <td>0.730446</td>\n",
       "      <td>1572.165649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        precision    recall  f1-score      support\n",
       "related                  0.786179  0.774017  0.779427  1572.172366\n",
       "request                  0.899284  0.795555  0.822057  1572.178321\n",
       "aid_related              0.810601  0.803270  0.805015  1572.161832\n",
       "medical_help             0.839252  0.700710  0.708548  1572.184122\n",
       "medical_products         0.943159  0.710000  0.722181  1572.192443\n",
       "search_and_rescue        0.918008  0.729401  0.752104  1572.198092\n",
       "security                 0.795347  0.717327  0.729566  1572.198779\n",
       "military                 0.666111  0.684342  0.675055  1572.192290\n",
       "water                    0.950010  0.790167  0.829515  1572.190229\n",
       "food                     0.943393  0.852828  0.884631  1572.188855\n",
       "shelter                  0.936517  0.795249  0.832450  1572.188779\n",
       "clothing                 0.937315  0.768161  0.805572  1572.197710\n",
       "money                    0.880387  0.698196  0.699992  1572.194809\n",
       "missing_people           0.995998  0.716460  0.731639  1572.198855\n",
       "refugees                 0.981949  0.713943  0.728493  1572.194809\n",
       "death                    0.938924  0.724247  0.745303  1572.191679\n",
       "other_aid                0.805608  0.678115  0.669676  1572.183359\n",
       "infrastructure_related   0.672962  0.687668  0.680204  1572.193893\n",
       "transport                0.889635  0.694369  0.695305  1572.190382\n",
       "buildings                0.874548  0.727207  0.747909  1572.191908\n",
       "electricity              0.989093  0.700883  0.703847  1572.196870\n",
       "tools                    0.698626  0.699389  0.699008  1572.199695\n",
       "hospitals                0.693826  0.697252  0.695533  1572.198626\n",
       "shops                    0.697520  0.698664  0.698091  1572.199389\n",
       "aid_centers              0.694854  0.697710  0.696278  1572.198855\n",
       "other_infrastructure     0.685624  0.693588  0.689574  1572.196794\n",
       "weather_related          0.910328  0.879635  0.891541  1572.181908\n",
       "floods                   0.962282  0.821337  0.862033  1572.190000\n",
       "storm                    0.913067  0.822865  0.853762  1572.189160\n",
       "fire                     0.696225  0.698321  0.697271  1572.199160\n",
       "earthquake               0.972911  0.965148  0.968957  1572.197328\n",
       "cold                     0.951869  0.740596  0.770007  1572.197023\n",
       "other_weather            0.895670  0.692493  0.690802  1572.192061\n",
       "direct_report            0.847525  0.719564  0.730446  1572.165649"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View results\n",
    "report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the Prediction Pipeline\n",
    "\n",
    "Now, we will save our prediction pipeline using the joblib library so that we can simply load it for prediction purposes in the future, without the need to train it from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Prediction_Pipeline.joblib']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(pipeline, 'Prediction_Pipeline.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and Testing the Pipeline\n",
    "\n",
    "Let's see how we can load and use the pipeline for prediction in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pipe_loaded = joblib.load('Prediction_Pipeline.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use this pipeline to classify the sample message below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are here in a repatriated village in zone menelas, We are in the sun and being burned by the sun, we ask that you help us please. We have children here.\n"
     ]
    }
   ],
   "source": [
    "n = 5\n",
    "trial = X_test.iloc[n:(n+1)]\n",
    "print(trial.values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this message, the model outputs are as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "related                   1\n",
       "request                   1\n",
       "aid_related               1\n",
       "medical_help              0\n",
       "medical_products          0\n",
       "search_and_rescue         0\n",
       "security                  0\n",
       "military                  0\n",
       "water                     0\n",
       "food                      0\n",
       "shelter                   0\n",
       "clothing                  0\n",
       "money                     0\n",
       "missing_people            0\n",
       "refugees                  0\n",
       "death                     0\n",
       "other_aid                 0\n",
       "infrastructure_related    0\n",
       "transport                 0\n",
       "buildings                 0\n",
       "electricity               0\n",
       "tools                     0\n",
       "hospitals                 0\n",
       "shops                     0\n",
       "aid_centers               0\n",
       "other_infrastructure      0\n",
       "weather_related           0\n",
       "floods                    0\n",
       "storm                     0\n",
       "fire                      0\n",
       "earthquake                0\n",
       "cold                      0\n",
       "other_weather             0\n",
       "direct_report             1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = Pipe_loaded.predict(trial)\n",
    "pd.Series(pred[0], index = ['related', 'request', 'aid_related', 'medical_help', 'medical_products',\n",
    "       'search_and_rescue', 'security', 'military', 'water', 'food', 'shelter',\n",
    "       'clothing', 'money', 'missing_people', 'refugees', 'death', 'other_aid',\n",
    "       'infrastructure_related', 'transport', 'buildings', 'electricity',\n",
    "       'tools', 'hospitals', 'shops', 'aid_centers', 'other_infrastructure',\n",
    "       'weather_related', 'floods', 'storm', 'fire', 'earthquake', 'cold',\n",
    "       'other_weather', 'direct_report'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we can see that for the sample message, 1 is predicted for 'related' since the message is a relevant emergency message. Further, the message is also classified as a request, aid related, and a direct report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
