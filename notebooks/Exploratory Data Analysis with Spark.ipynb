{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis with Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will be using Spark to perform some data analysis on our disaster messages dataset. We'll be using our training dataset, previously processed in 2 separate notebooks, namely 'Data Augmentation.ipynb' and 'Data Cleaning.ipynb'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting-up the Environment\n",
    "\n",
    "First, we will import the required libraries and set-up a Spark session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries and find spark\n",
    "import findspark\n",
    "findspark.init('spark/')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as func\n",
    "from pyspark.sql.functions import col,isnan, when, count, isnull, udf, struct, col\n",
    "from textblob import TextBlob\n",
    "from pyspark.sql.types import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.108:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>EDA</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fdf368c4a50>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start Spark session\n",
    "spark = SparkSession.builder.appName('EDA').getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the Data\n",
    "\n",
    "Next, we will start by using Spark to get an overview of the data, such as its schema, number of null values, as well as some statistical measures of the features.\n",
    "\n",
    "As an added note, the 'train.csv' file's delimiter was changed from the default \",\" to \"|\". This is to prevent any errors while reading the data, as our disaster messages have many commas, and in some cases, these could be misinterpreted as column separators. The codes to change the delimiters are not provided here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "df = spark.read.option('header','true').option('delimiter','|').csv('TrainSpark.csv',inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will print out the dataset schema below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- ID: integer (nullable = true)\n",
      " |-- date: timestamp (nullable = true)\n",
      " |-- labeled: integer (nullable = true)\n",
      " |-- message: string (nullable = true)\n",
      " |-- original: string (nullable = true)\n",
      " |-- language: string (nullable = true)\n",
      " |-- related: integer (nullable = true)\n",
      " |-- request: integer (nullable = true)\n",
      " |-- aid_related: integer (nullable = true)\n",
      " |-- medical_help: integer (nullable = true)\n",
      " |-- medical_products: integer (nullable = true)\n",
      " |-- search_and_rescue: integer (nullable = true)\n",
      " |-- security: integer (nullable = true)\n",
      " |-- military: integer (nullable = true)\n",
      " |-- water: integer (nullable = true)\n",
      " |-- food: integer (nullable = true)\n",
      " |-- shelter: integer (nullable = true)\n",
      " |-- clothing: integer (nullable = true)\n",
      " |-- money: integer (nullable = true)\n",
      " |-- missing_people: integer (nullable = true)\n",
      " |-- refugees: integer (nullable = true)\n",
      " |-- death: integer (nullable = true)\n",
      " |-- other_aid: integer (nullable = true)\n",
      " |-- infrastructure_related: integer (nullable = true)\n",
      " |-- transport: integer (nullable = true)\n",
      " |-- buildings: integer (nullable = true)\n",
      " |-- electricity: integer (nullable = true)\n",
      " |-- tools: integer (nullable = true)\n",
      " |-- hospitals: integer (nullable = true)\n",
      " |-- shops: integer (nullable = true)\n",
      " |-- aid_centers: integer (nullable = true)\n",
      " |-- other_infrastructure: integer (nullable = true)\n",
      " |-- weather_related: integer (nullable = true)\n",
      " |-- floods: integer (nullable = true)\n",
      " |-- storm: integer (nullable = true)\n",
      " |-- fire: integer (nullable = true)\n",
      " |-- earthquake: integer (nullable = true)\n",
      " |-- cold: integer (nullable = true)\n",
      " |-- other_weather: integer (nullable = true)\n",
      " |-- direct_report: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print Schema\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will extract a sample row, then the first 5 columns, to get a sense of the dataset. We also remove the unnecessary column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0--------------------------------------\n",
      " _c0                    | 0                    \n",
      " ID                     | 1                    \n",
      " date                   | 2010-01-01 00:00:00  \n",
      " labeled                | 0                    \n",
      " message                | With the cooperat... \n",
      " original               | null                 \n",
      " language               | en                   \n",
      " related                | 1                    \n",
      " request                | 0                    \n",
      " aid_related            | 1                    \n",
      " medical_help           | 0                    \n",
      " medical_products       | 0                    \n",
      " search_and_rescue      | 0                    \n",
      " security               | 0                    \n",
      " military               | 0                    \n",
      " water                  | 0                    \n",
      " food                   | 0                    \n",
      " shelter                | 0                    \n",
      " clothing               | 0                    \n",
      " money                  | 1                    \n",
      " missing_people         | 0                    \n",
      " refugees               | 0                    \n",
      " death                  | 0                    \n",
      " other_aid              | 0                    \n",
      " infrastructure_related | 0                    \n",
      " transport              | 0                    \n",
      " buildings              | 0                    \n",
      " electricity            | 0                    \n",
      " tools                  | 0                    \n",
      " hospitals              | 0                    \n",
      " shops                  | 0                    \n",
      " aid_centers            | 0                    \n",
      " other_infrastructure   | 0                    \n",
      " weather_related        | 1                    \n",
      " floods                 | 0                    \n",
      " storm                  | 1                    \n",
      " fire                   | 0                    \n",
      " earthquake             | 0                    \n",
      " cold                   | 0                    \n",
      " other_weather          | 1                    \n",
      " direct_report          | 0                    \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract sample row\n",
    "df.show(1, vertical = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------+--------------------+--------------------+--------+\n",
      "|               date|labeled|             message|            original|language|\n",
      "+-------------------+-------+--------------------+--------------------+--------+\n",
      "|2010-01-01 00:00:00|      0|With the cooperat...|                null|      en|\n",
      "|2010-01-01 00:00:00|      1|PEWODEN FIFTH SEC...|Pewoden 5em Seksy...|      ht|\n",
      "|2010-01-01 00:00:00|      1|Today on a call w...|                null|      en|\n",
      "|2010-01-01 00:00:00|      0|YANGON, Jul 08, 2...|                null|      en|\n",
      "|2010-01-01 00:00:00|      1|Throughout the ye...|                null|      en|\n",
      "|2010-01-01 00:00:00|      0|We have no pot in...|Nou pa gen chabon...|      ht|\n",
      "|2010-01-01 00:00:00|      1|**May 12** A 7.3 ...|                null|      en|\n",
      "|2010-01-02 00:00:00|      0|We would like to ...|renmen pou yo ta ...|      ht|\n",
      "|2010-01-02 00:00:00|      0|By secret ballot,...|                null|      en|\n",
      "|2010-01-02 00:00:00|      0|By August 29, kha...|                null|      en|\n",
      "|2010-01-02 00:00:00|      0|I am in Carefour ...|Mwen nan kafou fy...|      ht|\n",
      "|2010-01-02 00:00:00|      1|As of Monday, Feb...|                null|      en|\n",
      "|2010-01-02 00:00:00|      0|Here they live in...|                null|      en|\n",
      "|2010-01-02 00:00:00|      0|Slt. M sends cond...|Slt. M prezante k...|      ht|\n",
      "|2010-01-03 00:00:00|      0|i'd like to find ...|Mwen se youn nan ...|      ht|\n",
      "|2010-01-03 00:00:00|      1|Tens of thousands...|                null|      en|\n",
      "|2010-01-03 00:00:00|      0|The agreement was...|                null|      en|\n",
      "|2010-01-03 00:00:00|      0|Three landfill si...|                null|      en|\n",
      "|2010-01-03 00:00:00|      0|American Seahawk ...|                null|      en|\n",
      "|2010-01-03 00:00:00|      1|We are about 150 ...|Bonjour! Nous som...|      fr|\n",
      "+-------------------+-------+--------------------+--------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# View first 3 columns\n",
    "df.select(['date','labeled','message','original','language']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary column\n",
    "df = df.drop('_c0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We print out an overview of the dataset below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>ID</th>\n",
       "      <th>labeled</th>\n",
       "      <th>message</th>\n",
       "      <th>original</th>\n",
       "      <th>language</th>\n",
       "      <th>related</th>\n",
       "      <th>request</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>...</th>\n",
       "      <th>aid_centers</th>\n",
       "      <th>other_infrastructure</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count</td>\n",
       "      <td>20878</td>\n",
       "      <td>20878</td>\n",
       "      <td>20878</td>\n",
       "      <td>8074</td>\n",
       "      <td>20878</td>\n",
       "      <td>20878</td>\n",
       "      <td>20878</td>\n",
       "      <td>20878</td>\n",
       "      <td>20878</td>\n",
       "      <td>...</td>\n",
       "      <td>20878</td>\n",
       "      <td>20878</td>\n",
       "      <td>20878</td>\n",
       "      <td>20878</td>\n",
       "      <td>20878</td>\n",
       "      <td>20878</td>\n",
       "      <td>20878</td>\n",
       "      <td>20878</td>\n",
       "      <td>20878</td>\n",
       "      <td>20878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mean</td>\n",
       "      <td>10528.289778714436</td>\n",
       "      <td>0.2986876137561069</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7565379825653799</td>\n",
       "      <td>0.17051441708975956</td>\n",
       "      <td>0.4159881214675735</td>\n",
       "      <td>0.0792221477152984</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012357505508190439</td>\n",
       "      <td>0.047322540473225407</td>\n",
       "      <td>0.28091771242456176</td>\n",
       "      <td>0.08128173196666347</td>\n",
       "      <td>0.09450138902193697</td>\n",
       "      <td>0.011447456652936104</td>\n",
       "      <td>0.09478877287096465</td>\n",
       "      <td>0.020356355972794327</td>\n",
       "      <td>0.05450713669891752</td>\n",
       "      <td>0.19202030845866463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stddev</td>\n",
       "      <td>6073.987365748489</td>\n",
       "      <td>0.45769351845278344</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.42918187991325973</td>\n",
       "      <td>0.37609310753877667</td>\n",
       "      <td>0.4929032776223667</td>\n",
       "      <td>0.27009163835821753</td>\n",
       "      <td>...</td>\n",
       "      <td>0.11047797142759565</td>\n",
       "      <td>0.21233293927178754</td>\n",
       "      <td>0.44945814836508385</td>\n",
       "      <td>0.2732738350419775</td>\n",
       "      <td>0.2925320073185589</td>\n",
       "      <td>0.10638117521803214</td>\n",
       "      <td>0.2929299769218409</td>\n",
       "      <td>0.14121943901943926</td>\n",
       "      <td>0.22702109440957874</td>\n",
       "      <td>0.39389838937222443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>min</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>a</td>\n",
       "      <td>af</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max</td>\n",
       "      <td>21046</td>\n",
       "      <td>1</td>\n",
       "      <td>| News Update | Serious loss of life expected ...</td>\n",
       "      <td>zwen medikal nouriti dlo avan mwen te abite ma...</td>\n",
       "      <td>zu</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  summary                  ID              labeled  \\\n",
       "0   count               20878                20878   \n",
       "1    mean  10528.289778714436   0.2986876137561069   \n",
       "2  stddev   6073.987365748489  0.45769351845278344   \n",
       "3     min                   1                    0   \n",
       "4     max               21046                    1   \n",
       "\n",
       "                                             message  \\\n",
       "0                                              20878   \n",
       "1                                               None   \n",
       "2                                               None   \n",
       "3                                                      \n",
       "4  | News Update | Serious loss of life expected ...   \n",
       "\n",
       "                                            original language  \\\n",
       "0                                               8074    20878   \n",
       "1                                               None     None   \n",
       "2                                               None     None   \n",
       "3                                                  a       af   \n",
       "4  zwen medikal nouriti dlo avan mwen te abite ma...       zu   \n",
       "\n",
       "               related              request         aid_related  \\\n",
       "0                20878                20878               20878   \n",
       "1   0.7565379825653799  0.17051441708975956  0.4159881214675735   \n",
       "2  0.42918187991325973  0.37609310753877667  0.4929032776223667   \n",
       "3                    0                    0                   0   \n",
       "4                    1                    1                   1   \n",
       "\n",
       "          medical_help  ...           aid_centers  other_infrastructure  \\\n",
       "0                20878  ...                 20878                 20878   \n",
       "1   0.0792221477152984  ...  0.012357505508190439  0.047322540473225407   \n",
       "2  0.27009163835821753  ...   0.11047797142759565   0.21233293927178754   \n",
       "3                    0  ...                     0                     0   \n",
       "4                    1  ...                     1                     1   \n",
       "\n",
       "       weather_related               floods                storm  \\\n",
       "0                20878                20878                20878   \n",
       "1  0.28091771242456176  0.08128173196666347  0.09450138902193697   \n",
       "2  0.44945814836508385   0.2732738350419775   0.2925320073185589   \n",
       "3                    0                    0                    0   \n",
       "4                    1                    1                    1   \n",
       "\n",
       "                   fire           earthquake                  cold  \\\n",
       "0                 20878                20878                 20878   \n",
       "1  0.011447456652936104  0.09478877287096465  0.020356355972794327   \n",
       "2   0.10638117521803214   0.2929299769218409   0.14121943901943926   \n",
       "3                     0                    0                     0   \n",
       "4                     1                    1                     1   \n",
       "\n",
       "         other_weather        direct_report  \n",
       "0                20878                20878  \n",
       "1  0.05450713669891752  0.19202030845866463  \n",
       "2  0.22702109440957874  0.39389838937222443  \n",
       "3                    0                    0  \n",
       "4                    1                    1  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Describe\n",
    "df.describe().toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that there is one or more occurence(s) where the message column is blank. This does not provide additional value for us, and we will remove it later on. But for now, we'll leave it as it is.\n",
    "\n",
    "Next, we'll see how many null values are present in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>original</th>\n",
       "      <th>language</th>\n",
       "      <th>related</th>\n",
       "      <th>request</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>medical_products</th>\n",
       "      <th>search_and_rescue</th>\n",
       "      <th>security</th>\n",
       "      <th>...</th>\n",
       "      <th>aid_centers</th>\n",
       "      <th>other_infrastructure</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>12804</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   message  original  language  related  request  aid_related  medical_help  \\\n",
       "0        0     12804         0        0        0            0             0   \n",
       "\n",
       "   medical_products  search_and_rescue  security  ...  aid_centers  \\\n",
       "0                 0                  0         0  ...            0   \n",
       "\n",
       "   other_infrastructure  weather_related  floods  storm  fire  earthquake  \\\n",
       "0                     0                0       0      0     0           0   \n",
       "\n",
       "   cold  other_weather  direct_report  \n",
       "0     0              0              0  \n",
       "\n",
       "[1 rows x 37 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the number of null values\n",
    "df.select([count(when(isnull(c), c)).alias(c) for c in df.columns[3:]]).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we will create a new column to show the total number of categories, each message is classified into. This column is named 'Sum'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>date</th>\n",
       "      <th>labeled</th>\n",
       "      <th>message</th>\n",
       "      <th>original</th>\n",
       "      <th>language</th>\n",
       "      <th>related</th>\n",
       "      <th>request</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>...</th>\n",
       "      <th>other_infrastructure</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "      <th>Sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>With the cooperation of First Hawaiian Bank, t...</td>\n",
       "      <td>None</td>\n",
       "      <td>en</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>PEWODEN FIFTH SECTION OF THE DEPARTEMEN OF L'A...</td>\n",
       "      <td>Pewoden 5em Seksyon Depatman Atibonit ap fe no...</td>\n",
       "      <td>ht</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>Today on a call with Dr. Chan, Director Genera...</td>\n",
       "      <td>None</td>\n",
       "      <td>en</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>YANGON, Jul 08, 2008 (Xinhua via COMTEX News N...</td>\n",
       "      <td>None</td>\n",
       "      <td>en</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>Throughout the year there were growing signs o...</td>\n",
       "      <td>None</td>\n",
       "      <td>en</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID       date  labeled                                            message  \\\n",
       "0   1 2010-01-01        0  With the cooperation of First Hawaiian Bank, t...   \n",
       "1   2 2010-01-01        1  PEWODEN FIFTH SECTION OF THE DEPARTEMEN OF L'A...   \n",
       "2   3 2010-01-01        1  Today on a call with Dr. Chan, Director Genera...   \n",
       "3   4 2010-01-01        0  YANGON, Jul 08, 2008 (Xinhua via COMTEX News N...   \n",
       "4   5 2010-01-01        1  Throughout the year there were growing signs o...   \n",
       "\n",
       "                                            original language  related  \\\n",
       "0                                               None       en        1   \n",
       "1  Pewoden 5em Seksyon Depatman Atibonit ap fe no...       ht        1   \n",
       "2                                               None       en        1   \n",
       "3                                               None       en        1   \n",
       "4                                               None       en        1   \n",
       "\n",
       "   request  aid_related  medical_help  ...  other_infrastructure  \\\n",
       "0        0            1             0  ...                     0   \n",
       "1        0            0             0  ...                     0   \n",
       "2        0            1             1  ...                     0   \n",
       "3        0            1             0  ...                     1   \n",
       "4        0            1             0  ...                     0   \n",
       "\n",
       "   weather_related  floods  storm  fire  earthquake  cold  other_weather  \\\n",
       "0                1       0      1     0           0     0              1   \n",
       "1                1       0      0     0           1     0              0   \n",
       "2                0       0      0     0           0     0              0   \n",
       "3                1       1      1     0           0     0              0   \n",
       "4                0       0      0     0           0     0              0   \n",
       "\n",
       "   direct_report  Sum  \n",
       "0              0    5  \n",
       "1              1    3  \n",
       "2              0    3  \n",
       "3              0   11  \n",
       "4              0    2  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add new column to show number of categories for each message\n",
    "col_list = df.columns[7:]\n",
    "df = df.withColumn('Sum',sum([col(c) for c in col_list]))\n",
    "df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Queries Using Spark SQL\n",
    "\n",
    "In this section, we will use Spark SQL to perform some data analysis on our dataset. We will see if we can obtain any insights on the difference in message characteristics, based on their original language, relevancy, etc.\n",
    "\n",
    "First, we create a temporary view to query on, then try out a simple query by selecting specific columns from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create temporary view\n",
    "df.createOrReplaceTempView('MSGTable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+--------+\n",
      "|               date|             message|language|\n",
      "+-------------------+--------------------+--------+\n",
      "|2010-01-01 00:00:00|With the cooperat...|      en|\n",
      "|2010-01-01 00:00:00|PEWODEN FIFTH SEC...|      ht|\n",
      "|2010-01-01 00:00:00|Today on a call w...|      en|\n",
      "|2010-01-01 00:00:00|YANGON, Jul 08, 2...|      en|\n",
      "|2010-01-01 00:00:00|Throughout the ye...|      en|\n",
      "|2010-01-01 00:00:00|We have no pot in...|      ht|\n",
      "|2010-01-01 00:00:00|**May 12** A 7.3 ...|      en|\n",
      "|2010-01-02 00:00:00|We would like to ...|      ht|\n",
      "|2010-01-02 00:00:00|By secret ballot,...|      en|\n",
      "|2010-01-02 00:00:00|By August 29, kha...|      en|\n",
      "|2010-01-02 00:00:00|I am in Carefour ...|      ht|\n",
      "|2010-01-02 00:00:00|As of Monday, Feb...|      en|\n",
      "|2010-01-02 00:00:00|Here they live in...|      en|\n",
      "|2010-01-02 00:00:00|Slt. M sends cond...|      ht|\n",
      "|2010-01-03 00:00:00|i'd like to find ...|      ht|\n",
      "|2010-01-03 00:00:00|Tens of thousands...|      en|\n",
      "|2010-01-03 00:00:00|The agreement was...|      en|\n",
      "|2010-01-03 00:00:00|Three landfill si...|      en|\n",
      "|2010-01-03 00:00:00|American Seahawk ...|      en|\n",
      "|2010-01-03 00:00:00|We are about 150 ...|      fr|\n",
      "+-------------------+--------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test query\n",
    "query = \"SELECT date, message, language FROM MSGTable\"\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we extract the total messages by dates and month, then sort them by descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------+\n",
      "|               date|TotalMessages|\n",
      "+-------------------+-------------+\n",
      "|2018-08-28 00:00:00|           19|\n",
      "|2014-08-01 00:00:00|           17|\n",
      "|2014-05-20 00:00:00|           15|\n",
      "|2011-03-11 00:00:00|           15|\n",
      "|2011-11-22 00:00:00|           14|\n",
      "|2017-08-29 00:00:00|           14|\n",
      "|2015-12-17 00:00:00|           14|\n",
      "|2010-12-18 00:00:00|           14|\n",
      "|2010-05-10 00:00:00|           14|\n",
      "|2019-09-21 00:00:00|           14|\n",
      "|2018-08-15 00:00:00|           14|\n",
      "|2012-06-02 00:00:00|           14|\n",
      "|2017-02-01 00:00:00|           14|\n",
      "|2014-11-25 00:00:00|           14|\n",
      "|2011-01-08 00:00:00|           13|\n",
      "|2014-10-31 00:00:00|           13|\n",
      "|2015-05-01 00:00:00|           13|\n",
      "|2010-04-22 00:00:00|           13|\n",
      "|2012-11-17 00:00:00|           13|\n",
      "|2011-01-02 00:00:00|           13|\n",
      "+-------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Messages by date\n",
    "query = \"SELECT date, COUNT(ID) as TotalMessages FROM MSGTable GROUP BY date ORDER BY TotalMessages DESC\"\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+-------------+\n",
      "|Mth|  Yr|TotalMessages|\n",
      "+---+----+-------------+\n",
      "|  6|2019|          205|\n",
      "|  8|2018|          204|\n",
      "|  5|2011|          200|\n",
      "| 11|2012|          200|\n",
      "|  4|2010|          200|\n",
      "|  7|2015|          199|\n",
      "|  3|2010|          198|\n",
      "| 10|2016|          196|\n",
      "|  3|2016|          195|\n",
      "|  6|2017|          194|\n",
      "|  1|2012|          194|\n",
      "| 12|2015|          194|\n",
      "|  1|2011|          193|\n",
      "|  9|2019|          193|\n",
      "|  9|2015|          193|\n",
      "|  8|2010|          192|\n",
      "|  5|2019|          191|\n",
      "| 11|2011|          191|\n",
      "|  1|2016|          190|\n",
      "|  6|2012|          189|\n",
      "+---+----+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Messages by month and year\n",
    "query = \"SELECT MONTH(date) AS Mth, YEAR(date) AS Yr, COUNT(ID) AS TotalMessages FROM MSGTable GROUP BY Mth, Yr ORDER BY TotalMessages DESC\"\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also group the messages by languages to see the most popular languages used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------+\n",
      "|language|TotalMessages|\n",
      "+--------+-------------+\n",
      "|      en|        13178|\n",
      "|      ht|         5084|\n",
      "|      fr|         1464|\n",
      "|      nl|          144|\n",
      "|      id|          109|\n",
      "|      ms|           94|\n",
      "|      eo|           83|\n",
      "|      es|           73|\n",
      "|      fi|           52|\n",
      "|      br|           51|\n",
      "|      sl|           47|\n",
      "|      it|           45|\n",
      "|      rw|           44|\n",
      "|      sw|           42|\n",
      "|      no|           38|\n",
      "|      tl|           36|\n",
      "|      jv|           28|\n",
      "|      de|           26|\n",
      "|      da|           24|\n",
      "|      eu|           23|\n",
      "+--------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Messages by language\n",
    "query = \"SELECT language, COUNT(ID) as TotalMessages FROM MSGTable GROUP BY language ORDER BY TotalMessages DESC\"\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that English is the most popular language by a large margin, followed by Haiti, then French. Next, we find out the number of labeled and unlabelled messages for each language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+-------------+\n",
      "|language|labeled|TotalMessages|\n",
      "+--------+-------+-------------+\n",
      "|      en|      0|         9236|\n",
      "|      en|      1|         3942|\n",
      "|      ht|      0|         3527|\n",
      "|      ht|      1|         1557|\n",
      "|      fr|      0|         1080|\n",
      "|      fr|      1|          384|\n",
      "|      nl|      0|          100|\n",
      "|      id|      0|           73|\n",
      "|      ms|      0|           64|\n",
      "|      eo|      0|           59|\n",
      "|      es|      0|           48|\n",
      "|      nl|      1|           44|\n",
      "|      fi|      0|           37|\n",
      "|      id|      1|           36|\n",
      "|      br|      0|           36|\n",
      "|      sl|      0|           35|\n",
      "|      rw|      0|           32|\n",
      "|      it|      0|           31|\n",
      "|      ms|      1|           30|\n",
      "|      sw|      0|           27|\n",
      "+--------+-------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Messages by language and labeled category\n",
    "query = \"SELECT language, labeled, COUNT(ID) as TotalMessages FROM MSGTable GROUP BY language,labeled ORDER BY TotalMessages DESC\"\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following on, we can use the query below to observe the percentage of labeled messages for each language. We can see that this figure is around 70%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+-------------+------------------+\n",
      "|language|labeled|TotalMessages|        Percentage|\n",
      "+--------+-------+-------------+------------------+\n",
      "|      en|      0|         9236| 70.08650781605706|\n",
      "|      en|      1|         3942|29.913492183942935|\n",
      "|      ht|      0|         3527| 69.37450826121164|\n",
      "|      ht|      1|         1557| 30.62549173878836|\n",
      "|      fr|      0|         1080| 73.77049180327869|\n",
      "|      fr|      1|          384|26.229508196721312|\n",
      "|      nl|      0|          100| 69.44444444444444|\n",
      "|      nl|      1|           44|30.555555555555557|\n",
      "|      id|      0|           73| 66.97247706422019|\n",
      "|      id|      1|           36| 33.02752293577982|\n",
      "|      ms|      0|           64| 68.08510638297872|\n",
      "|      ms|      1|           30|31.914893617021278|\n",
      "|      eo|      0|           59| 71.08433734939759|\n",
      "|      eo|      1|           24|28.915662650602407|\n",
      "|      es|      0|           48| 65.75342465753424|\n",
      "|      es|      1|           25| 34.24657534246575|\n",
      "|      fi|      0|           37| 71.15384615384616|\n",
      "|      fi|      1|           15|28.846153846153843|\n",
      "|      br|      0|           36| 70.58823529411765|\n",
      "|      br|      1|           15|29.411764705882355|\n",
      "+--------+-------+-------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Messages by language and labeled category, along with the percentage\n",
    "query = '''\n",
    "WITH LangTotal As\n",
    "(\n",
    "    SELECT language, COUNT(ID) as TotalMessages FROM MSGTable GROUP BY language ORDER BY TotalMessages DESC\n",
    "),\n",
    "LangLabeled As\n",
    "(\n",
    "    SELECT language, labeled, COUNT(ID) as TotalMessages FROM MSGTable GROUP BY language,labeled ORDER BY TotalMessages DESC\n",
    ")\n",
    "SELECT\n",
    "    L.language, L.labeled, L.TotalMessages, L.TotalMessages / T.TotalMessages * 100.0 As Percentage\n",
    "FROM\n",
    "    LangLabeled L\n",
    "LEFT JOIN\n",
    "    LangTotal T\n",
    "ON\n",
    "    L.language = T.language\n",
    "ORDER BY T.TotalMessages DESC, L.labeled\n",
    "'''\n",
    "\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we extract the number and percentage of related messages for each language. A related message is when the message is a relevant emergency ticket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+-------------+------------------+\n",
      "|language|related|TotalMessages|        Percentage|\n",
      "+--------+-------+-------------+------------------+\n",
      "|      en|      1|        10752| 81.59052967066323|\n",
      "|      en|      0|         2426|18.409470329336774|\n",
      "|      ht|      1|         3574| 70.29897718332022|\n",
      "|      ht|      0|         1510|29.701022816679778|\n",
      "|      fr|      1|          764| 52.18579234972678|\n",
      "|      fr|      0|          700| 47.81420765027322|\n",
      "|      nl|      1|           87|60.416666666666664|\n",
      "|      nl|      0|           57| 39.58333333333333|\n",
      "|      id|      1|           71| 65.13761467889908|\n",
      "|      id|      0|           38|34.862385321100916|\n",
      "|      ms|      1|           72| 76.59574468085107|\n",
      "|      ms|      0|           22|23.404255319148938|\n",
      "|      eo|      1|           43| 51.80722891566265|\n",
      "|      eo|      0|           40| 48.19277108433735|\n",
      "|      es|      1|           43|  58.9041095890411|\n",
      "|      es|      0|           30|  41.0958904109589|\n",
      "|      fi|      1|           22| 42.30769230769231|\n",
      "|      fi|      0|           30|57.692307692307686|\n",
      "|      br|      1|           28| 54.90196078431373|\n",
      "|      br|      0|           23| 45.09803921568628|\n",
      "+--------+-------+-------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Messages by language and related category, along with the percentage\n",
    "query = '''\n",
    "WITH LangTotal As\n",
    "(\n",
    "    SELECT language, COUNT(ID) as TotalMessages FROM MSGTable GROUP BY language ORDER BY TotalMessages DESC\n",
    "),\n",
    "RelLabeled As\n",
    "(\n",
    "    SELECT language, related, COUNT(ID) as TotalMessages FROM MSGTable GROUP BY language, related ORDER BY TotalMessages DESC\n",
    ")\n",
    "SELECT\n",
    "    L.language, L.related, L.TotalMessages, L.TotalMessages / T.TotalMessages * 100.0 As Percentage\n",
    "FROM\n",
    "    RelLabeled L\n",
    "LEFT JOIN\n",
    "    LangTotal T\n",
    "ON\n",
    "    L.language = T.language\n",
    "ORDER BY T.TotalMessages DESC, L.related DESC\n",
    "'''\n",
    "\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the 20 most popular languages, we observe that English has the highest related percentage, whereas Finnish has the lowest. Finally, we find out the average number of classes each message is classified into, for each language. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------+------------------+\n",
      "|language|Total_Messages|   MessageClassAvg|\n",
      "+--------+--------------+------------------+\n",
      "|      en|         13178| 2.555091819699499|\n",
      "|      ht|          5084|2.4878048780487805|\n",
      "|      fr|          1464|1.4624316939890711|\n",
      "|      nl|           144|1.9791666666666667|\n",
      "|      id|           109| 2.091743119266055|\n",
      "|      ms|            94| 3.617021276595745|\n",
      "|      eo|            83|1.2048192771084338|\n",
      "|      es|            73| 1.356164383561644|\n",
      "|      fi|            52|1.3461538461538463|\n",
      "|      br|            51|1.3725490196078431|\n",
      "|      sl|            47|2.6382978723404253|\n",
      "|      it|            45|1.1333333333333333|\n",
      "|      rw|            44| 4.454545454545454|\n",
      "|      sw|            42|3.4285714285714284|\n",
      "|      no|            38| 1.131578947368421|\n",
      "|      tl|            36|2.1666666666666665|\n",
      "|      jv|            28|              3.75|\n",
      "|      de|            26|1.2692307692307692|\n",
      "|      da|            24|0.6666666666666666|\n",
      "|      eu|            23|2.1739130434782608|\n",
      "+--------+--------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Messages by language, along with average number of classes for each message\n",
    "query = \"SELECT language, COUNT(ID) AS Total_Messages, AVG(MSGTable.Sum) AS MessageClassAvg FROM MSGTable GROUP BY language ORDER BY Total_Messages DESC\"\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the 20 most popular languages, we observe that Javanese is highest in this category, whereas Dannish is lowest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Data Analysis with Spark\n",
    "\n",
    "In this final section, we will be making use of Spark's UDF to apply functions defined using other Python libraries, to our Spark dataframe. We'll be focusing more on analysing the text-related features here.\n",
    "\n",
    "First, we create a duplicate dataframe, with only relevant features, to perform our operations on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------+--------------------+--------+-------+\n",
      "|               date|labeled|             message|language|related|\n",
      "+-------------------+-------+--------------------+--------+-------+\n",
      "|2010-01-01 00:00:00|      0|With the cooperat...|      en|      1|\n",
      "|2010-01-01 00:00:00|      1|PEWODEN FIFTH SEC...|      ht|      1|\n",
      "|2010-01-01 00:00:00|      1|Today on a call w...|      en|      1|\n",
      "|2010-01-01 00:00:00|      0|YANGON, Jul 08, 2...|      en|      1|\n",
      "|2010-01-01 00:00:00|      1|Throughout the ye...|      en|      1|\n",
      "|2010-01-01 00:00:00|      0|We have no pot in...|      ht|      1|\n",
      "|2010-01-01 00:00:00|      1|**May 12** A 7.3 ...|      en|      1|\n",
      "|2010-01-02 00:00:00|      0|We would like to ...|      ht|      1|\n",
      "|2010-01-02 00:00:00|      0|By secret ballot,...|      en|      0|\n",
      "|2010-01-02 00:00:00|      0|By August 29, kha...|      en|      0|\n",
      "|2010-01-02 00:00:00|      0|I am in Carefour ...|      ht|      1|\n",
      "|2010-01-02 00:00:00|      1|As of Monday, Feb...|      en|      1|\n",
      "|2010-01-02 00:00:00|      0|Here they live in...|      en|      1|\n",
      "|2010-01-02 00:00:00|      0|Slt. M sends cond...|      ht|      1|\n",
      "|2010-01-03 00:00:00|      0|i'd like to find ...|      ht|      1|\n",
      "|2010-01-03 00:00:00|      1|Tens of thousands...|      en|      1|\n",
      "|2010-01-03 00:00:00|      0|The agreement was...|      en|      1|\n",
      "|2010-01-03 00:00:00|      0|Three landfill si...|      en|      0|\n",
      "|2010-01-03 00:00:00|      0|American Seahawk ...|      en|      1|\n",
      "|2010-01-03 00:00:00|      1|We are about 150 ...|      fr|      1|\n",
      "+-------------------+-------+--------------------+--------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select specific columns as new df\n",
    "df_anl = df.select(['date', 'labeled', 'message', 'language', 'related'])\n",
    "df_anl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define 4 helper functions below to help us with our analysis. The first and second helper functions calculate the number of words and characters in each message, respectively, whereas the third helper function calculates the word density, which is obtained by dividing the number of words by the number of characters. Finally, in the fourth helper function, we determine the polarity of each message by using the textblob library in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions in Python\n",
    "\n",
    "# Get number of words\n",
    "def word_count(msg):\n",
    "    word_count = len(msg.split())\n",
    "    \n",
    "    return word_count\n",
    "\n",
    "# Get number of chars\n",
    "def char_count(msg):\n",
    "    char_count = len(msg.replace(\" \",\"\"))\n",
    "    \n",
    "    return char_count\n",
    "\n",
    "# Divide word count by char count to obtain word density\n",
    "def word_density(msg):\n",
    "    word_count = len(msg.split())\n",
    "    char_count = len(msg.replace(\" \",\"\"))\n",
    "    word_density = word_count/char_count\n",
    "    \n",
    "    return word_density\n",
    "\n",
    "# Get polarity of each message\n",
    "def get_polarity(msg):\n",
    "    try:\n",
    "        pol = TextBlob(msg).sentiment.polarity\n",
    "    except:\n",
    "        pol = 0.0\n",
    "    return pol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we create 4 Spark UDFs, each corresponding to one helper function defined in the previous cell, and define the output data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Spark UDF\n",
    "word_count_udf = udf(lambda msg: word_count(msg), IntegerType())\n",
    "char_count_udf = udf(lambda msg: char_count(msg), IntegerType())\n",
    "word_density_udf = udf(lambda msg: word_density(msg), FloatType())\n",
    "get_polarity_udf = udf(lambda msg: get_polarity(msg), FloatType())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll apply the UDFs on our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------+--------------------+--------+-------+----------+----------+------------+------------+\n",
      "|               date|labeled|             message|language|related|word_count|char_count|word_density|    polarity|\n",
      "+-------------------+-------+--------------------+--------+-------+----------+----------+------------+------------+\n",
      "|2010-01-01 00:00:00|      0|With the cooperat...|      en|      1|        32|       198|  0.16161616| 0.016666668|\n",
      "|2010-01-01 00:00:00|      1|PEWODEN FIFTH SEC...|      ht|      1|        29|       128|   0.2265625|         0.5|\n",
      "|2010-01-01 00:00:00|      1|Today on a call w...|      en|      1|        33|       161|  0.20496894|        0.15|\n",
      "|2010-01-01 00:00:00|      0|YANGON, Jul 08, 2...|      en|      1|        51|       290|  0.17586207|         0.0|\n",
      "|2010-01-01 00:00:00|      1|Throughout the ye...|      en|      1|        41|       247|   0.1659919| -0.29166666|\n",
      "|2010-01-01 00:00:00|      0|We have no pot in...|      ht|      1|        15|        54|   0.2777778|         0.0|\n",
      "|2010-01-01 00:00:00|      1|**May 12** A 7.3 ...|      en|      1|        19|       113|  0.16814159|  0.21666667|\n",
      "|2010-01-02 00:00:00|      0|We would like to ...|      ht|      1|        17|        72|   0.2361111|         0.0|\n",
      "|2010-01-02 00:00:00|      0|By secret ballot,...|      en|      0|        29|       145|         0.2| -0.13333334|\n",
      "|2010-01-02 00:00:00|      0|By August 29, kha...|      en|      0|        11|        51|  0.21568628|         0.0|\n",
      "|2010-01-02 00:00:00|      0|I am in Carefour ...|      ht|      1|        21|       113|  0.18584071|         0.0|\n",
      "|2010-01-02 00:00:00|      1|As of Monday, Feb...|      en|      1|        18|        96|      0.1875|         0.0|\n",
      "|2010-01-02 00:00:00|      0|Here they live in...|      en|      1|        33|       149|  0.22147651| 0.045454547|\n",
      "|2010-01-02 00:00:00|      0|Slt. M sends cond...|      ht|      1|        29|       127|  0.22834645|         0.0|\n",
      "|2010-01-03 00:00:00|      0|i'd like to find ...|      ht|      1|        15|        57|   0.2631579|         0.0|\n",
      "|2010-01-03 00:00:00|      1|Tens of thousands...|      en|      1|        18|        94|  0.19148937|-0.033333335|\n",
      "|2010-01-03 00:00:00|      0|The agreement was...|      en|      1|        33|       168|  0.19642857|         0.0|\n",
      "|2010-01-03 00:00:00|      0|Three landfill si...|      en|      0|        33|       181|  0.18232045|        -0.1|\n",
      "|2010-01-03 00:00:00|      0|American Seahawk ...|      en|      1|        16|       104|  0.15384616|        0.05|\n",
      "|2010-01-03 00:00:00|      1|We are about 150 ...|      fr|      1|        40|       135|   0.2962963|         0.0|\n",
      "+-------------------+-------+--------------------+--------+-------+----------+----------+------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Apply Spark udf into our data\n",
    "df_anl = df_anl.select('date','labeled','message','language','related',\n",
    "                       word_count_udf('message').alias('word_count'),\n",
    "                       char_count_udf('message').alias('char_count'),\n",
    "                       word_density_udf('message').alias('word_density'),\n",
    "                       get_polarity_udf('message').alias('polarity'))\n",
    "df_anl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Earlier in the notebook, we observed that there is one or more occurrences where the message column is left blank. Since this is not useful to us, and in addition, will cause an error when we analyse the dataframe if left present (word density will be undefined as the char count, is divided by the word count, which in this case, is zero.), we will remove the case(s) where the message column is blank, with the command below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unnecessary row(s)\n",
    "df_anl = df_anl.where(df_anl.word_count != 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll get an overview of our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+-------------------+-------------------+\n",
      "|summary|        word_count|        char_count|       word_density|           polarity|\n",
      "+-------+------------------+------------------+-------------------+-------------------+\n",
      "|  count|             20877|             20877|              20877|              20877|\n",
      "|   mean| 23.75858600373617| 121.2066867844997|0.20574134856039755|0.04839525768272292|\n",
      "| stddev|31.245594649025374|170.54404693828388|0.03954463710951681|0.22282905891324675|\n",
      "|    min|                 1|                 6|        0.010416667|               -1.0|\n",
      "|    max|              1686|              9144|          0.4090909|                1.0|\n",
      "+-------+------------------+------------------+-------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Describe df\n",
    "df_anl.select('word_count','char_count','word_density','polarity').describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll see how the features differ between different languages. We observe that messages originally in English generally has the highest word and character count, whereas messages originally in Polish have the lowest count when translated. \n",
    "\n",
    "Further, the average word desnity do not seem to differ by much between languages. For polarity, messages in Polish seem to have a higher average score relatively, compared to other languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+------------------+-------------------+--------------------+\n",
      "|language|   avg(word_count)|   avg(char_count)|  avg(word_density)|       avg(polarity)|\n",
      "+--------+------------------+------------------+-------------------+--------------------+\n",
      "|      en|27.852621992866357|149.92297184488123| 0.1892106915671663|0.039803210610380765|\n",
      "|      vi|               9.0|              47.0|0.19148936867713928|                 0.0|\n",
      "|      nb| 9.222222222222221|              37.0| 0.2550584276517232| 0.11666666467984517|\n",
      "|      sl| 10.46808510638298| 47.53191489361702|0.23426036520841273|-0.00854932389994885|\n",
      "|      ro|13.714285714285714| 66.28571428571429| 0.2082196261201586|-0.02857142899717...|\n",
      "|      lv|               9.0|              50.0|0.18000000715255737|                 0.0|\n",
      "|      pl|               5.5|              34.0|0.15428824350237846| 0.30000001192092896|\n",
      "|      sk|              11.0|40.666666666666664|0.27828853329022724|                 0.0|\n",
      "|      pt|               8.0|            44.125|0.18230747245252132|0.036979167722165585|\n",
      "|      oc|              12.2|              58.6|  0.204386904835701|-0.04000000059604645|\n",
      "|      tl|15.027777777777779| 68.80555555555556| 0.2273387706114186|0.057986110707537994|\n",
      "|      sw|18.071428571428573| 84.07142857142857|0.21307296199457987|-0.07583864929065817|\n",
      "|      ms|18.670212765957448| 85.64893617021276| 0.2220191093201333|0.027837867511713757|\n",
      "|      jv|14.535714285714286|             64.75|0.22670884696500643| 0.04230493786079543|\n",
      "|      cs| 8.714285714285714|38.857142857142854|0.22066389662878855| 0.10535714136702674|\n",
      "|      qu|              20.0|             105.0|  0.190476194024086|                 0.0|\n",
      "|      mg|              11.0|              45.5|0.24006783217191696|                 0.0|\n",
      "|      tr|             7.875|              32.5| 0.2440127618610859| 0.08750000037252903|\n",
      "|      de| 9.038461538461538| 39.53846153846154|0.22872796941262025|0.010283119403398953|\n",
      "|      br| 14.03921568627451|62.745098039215684| 0.2228004686972674| 0.05310882021691285|\n",
      "+--------+------------------+------------------+-------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Text features by language\n",
    "df_anl.groupBy('language').mean('word_count','char_count','word_density','polarity').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also observe them in related and unrelated messages. We observe that related messages are on average longer than unrelated ones, and have a slightly lower polarity score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+-------------------+-------------------+\n",
      "|related|   avg(word_count)|   avg(char_count)|  avg(word_density)|      avg(polarity)|\n",
      "+-------+------------------+------------------+-------------------+-------------------+\n",
      "|      1|25.262631379004684|129.52633911612006| 0.2035966490507876|0.03941325727495277|\n",
      "|      0|19.085185913830415|  95.3556954554397|0.21240540208288025|0.07630431029738387|\n",
      "+-------+------------------+------------------+-------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Text features by related category\n",
    "df_anl.groupBy('related').mean('word_count','char_count','word_density','polarity').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we'll take a look at the messages with the highest (most positive sentiment) and lowest (most negative sentiment) polarity scores below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|message                                                                                                                                                                                                                      |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|Ebola causes severe fever and, in the worst cases, unstoppable bleeding.                                                                                                                                                     |\n",
      "|Based on what happened, if we do not learn anything from it tomorrow will be worst.                                                                                                                                          |\n",
      "|Omg..Earthquake in Haiti! I ve always hated earthquakes. God bless y all!                                                                                                                                                    |\n",
      "|The country's worst post-World War II disaster was compounded by reactor meltdowns at the Fukushima nuclear power plant, which sent tens of thousands of people fleeing from radiation.                                      |\n",
      "|Will they bring tants for us. If it rains. It will be terrible for us.                                                                                                                                                       |\n",
      "|omg just heard it in the news about the horrible earthquake in haiti! 0_0                                                                                                                                                    |\n",
      "|Sudan's health ministry is distributing chlorine to sterilise water, repairing latrines and spraying insecticides to try to stop the spread of cholera and malaria after the worst floods in living memory.                  |\n",
      "|The Federation and CRC have responded to requests from the NMC for additional supplies of anti-malarial drug treatments to supplement the national stocks in the worst affected areas.                                       |\n",
      "|haitian earthquake is a terrible tragedy                                                                                                                                                                                     |\n",
      "|In response to North Korea's devastating artillery attack on Yeonpyeong Island on Tuesday, South Korea has suspended aid shipments of food and cement to the North's flood-stricken Shinuiju region.                         |\n",
      "|. .. i with nothing. i am really miserable, please do something.                                                                                                                                                             |\n",
      "|The groups ruthlessly hijacked religion to control territory and resources, brutalize women and girls and slaughter minorities.                                                                                              |\n",
      "|Awful pics from Haiti earthquake on Sky                                                                                                                                                                                      |\n",
      "|this is there is a terrible earthquake still. Please help me to know what must I do                                                                                                                                          |\n",
      "|Words cannot express how terrible it is to see the devastation caused my Sandy.We weathered the storm! @TeamCNNEE @TeamCNN @HLNTV Thx @BobVanDillen &amp; @robmarcianoCNN for helping me through #Sandy! http://t.co/xHXH2gio|\n",
      "|We're very miserable. Please make a message for us                                                                                                                                                                           |\n",
      "|GROUP DWASIMEN doing always act of kindness, his never lost,the worst never lost before GOD.                                                                                                                                 |\n",
      "|Horrible earthquake of the coast of Haiti everyone pray for those effect by it                                                                                                                                               |\n",
      "|In Turkana, one of the worst affected areas, hundreds of homes have been washed away by floods or buried under landslides.                                                                                                   |\n",
      "|Food water batteries procured . Outdoor furniture secured . #Sandy can do her worst .                                                                                                                                        |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Messages with lowest polarity (most negative)\n",
    "df_anl.orderBy('polarity').select('message').show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|message                                                                                                                                                                                                                                                           |\n",
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|Critics point out that what Somalia will have after August 20 will not be a perfect representative democracy.                                                                                                                                                     |\n",
      "|The greatest need after the devastation wreaked by the 7.6 magnitude quake was for field hospitals, water purification and blankets, the spokeswoman said.                                                                                                        |\n",
      "|Outreach officers visited each home, teaching homeowners about the septic systems and how to maintain them, assisting in deciding on the best location and layout for their gardens and providing information on how best to care for plants.                     |\n",
      "|We need change, time after time, weeks after weeks, month after month, years after years, and HAITI, has been the best!.                                                                                                                                          |\n",
      "|YGovCuomo I think ur doing an awesome job dealing w the gas crisis and keeping NYers informed #Sandy                                                                                                                                                              |\n",
      "|Passing out food , collecting food , getting things to people who need , I JUST WANT TO HELP BECAUSE THESE PEOPLE NEED OUR HELP I SEE THEM ON THE NEWS . I CAN FLY OUT FROM LOS ANGELES , I NEED SOMEWHERE TO BE STATIONED AND WORKING HELPING THOSE PEOPLE ASAP !|\n",
      "|RT jeffbrooks Best Twitter source on #Haiti quake nprnews haiti earthquake lots of news but not a firehose.                                                                                                                                                       |\n",
      "|Digicel @@ Digicel @@ Digicel I great you!                                                                                                                                                                                                                        |\n",
      "|We are very happy to have recieved an answer to our message. We hope we will find help. Thank you god bless                                                                                                                                                       |\n",
      "|10 retention and detention basins were utilized at the best point of time to ease flood pressure upon the mainstream of Huaihe River .                                                                                                                            |\n",
      "|The calamity led to separatist insurgencies, with legendary guerrilla leader Laldenga forming the Mizo Famine Front.                                                                                                                                              |\n",
      "|RT efinka: http://tinyurl.com/yhy5zlu\\n\\n- Santiago makes for an impressive program - nothing to fear but fear itself                                                                                                                                             |\n",
      "|I got the message.  I would be very happy to find a job to help my family because they have no means. I have no CV, I study phamacology at my school                                                                                                              |\n",
      "|The wind is moving my house , Lol chill sandy!!!Safe in Midtown with my hurricane team. Seltzer and gossip mags for everyone! #sandy #UWS #homeoffice @laceelazoff @keltiemorrison                                                                                |\n",
      "|Welcome to Chile, country attended by his owner! (Como les qued‚àö‚â•? Tom‚àö¬© clases con luchito jara estos meses!).                                                                                                                                            |\n",
      "|Why wouldn't there be a hurricane coming here in time for my flight to Orlando? _This storm is perfect to go surfing _ .                                                                                                                                          |\n",
      "|Happy hurricane wishes ! http://t.co/KDwz7Qjf                                                                                                                                                                                                                     |\n",
      "|spoke to her , greatest needs are food and clothing . lost everything . entered into database .                                                                                                                                                                   |\n",
      "|I plan on driving up Thanksgiving morning from VA - what ever the need is at that time I hope to bring in my car - supplies / food / toys / products etc Please let me know what would be best - I will keep in touch                                             |\n",
      "|What is the greatest magnitude that an aftershock can be?                                                                                                                                                                                                         |\n",
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Messages with highest polarity (most positive)\n",
    "df_anl.orderBy('polarity', ascending = False).select('message').show(truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that messages with lower polarity scores do indeed seem more negative than those with higher polarity scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End Session\n",
    "\n",
    "This marks an end to our EDA process with Spark. Before finishing, we'll stop the Spark session with the command below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop Spark session\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
